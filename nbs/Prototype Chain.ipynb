{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c0daac-daea-48df-b68c-2b5e86455eca",
   "metadata": {},
   "source": [
    "## A Simple RAG Chain\n",
    "This notebook contains experiments for building a simple RAG chain which can answer user's questions regarding\n",
    "[Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People](https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf) and [National Institute of Standards and Technology (NIST) Artificial Intelligent Risk Management Framework](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600-1.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c61936-3968-4aa1-89ae-38275b9e0c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tiktoken\n",
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_openai.llms import OpenAI\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains.conversation.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.messages import SystemMessage, AIMessage, HumanMessage\n",
    "from langchain_core.prompts import (ChatMessagePromptTemplate, SystemMessagePromptTemplate, \n",
    "                                    AIMessagePromptTemplate, HumanMessagePromptTemplate)\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.output_parsers import OutputFixingParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87b7897-9865-4def-8644-8f7390394c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv; _ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39da8754-0211-4f15-8749-881b74e425c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio; nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209ab190-dac6-4935-befa-137efc9fd3bf",
   "metadata": {},
   "source": [
    "## A Simple RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4ef2342-2159-4b88-b40b-e44d7d55a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Please answer the question below using the provided context. If the question cannnot be answered\n",
    "using the context, politely state that you can't answer that question.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "994b81bd-0795-4a1f-ba26-0fd039824052",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "retriever = QdrantVectorStore.from_existing_collection(\n",
    "    collection_name='ai_ethics_te3_small',\n",
    "    embedding=embedding,\n",
    "    url=os.environ.get('QDRANT_DB'),\n",
    "    api_key=os.environ.get('QDRANT_API_KEY')\n",
    ").as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "651ec27c-8743-4446-b977-6225fd28d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a80a2bc-b3fc-4555-8692-1e77d260a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = ({'context': retriever, 'question': RunnablePassthrough()}\n",
    "             | prompt\n",
    "             | llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faa3b6e3-fc62-4ff3-8504-f9e481f06d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def message(message):\n",
    "    async for r in rag_chain.astream(message):\n",
    "        print(r.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9265e9c8-f594-4d40-9b85-873d2695bb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AI Bill of Rights, as described in the provided context, is a framework published by the White House Office of Science and Technology Policy. It aims to support the development of policies and practices that protect civil rights and promote democratic values in the building, deployment, and governance of automated systems. The document is non-binding and does not constitute U.S. government policy. It outlines principles to guide the use of automated systems, particularly those that have the potential to impact individuals' or communities' rights, opportunities, or access to critical resources or services.\n",
      "\n",
      "If you need more specific details or further elaboration on the principles and practices included in the AI Bill of Rights, please let me know!"
     ]
    }
   ],
   "source": [
    "await message(\"What is the AI Bill of rights?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cdd85d2-7cec-4df3-a6c9-d77f1e5795fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context provided outlines several principles and frameworks aimed at making AI systems safer and more effective. Here are some key strategies mentioned:\n",
      "\n",
      "1. **Adherence to Principles**: Federal agencies are required to follow principles such as ensuring AI is lawful, purposeful, accurate, reliable, safe, secure, understandable, responsible, traceable, regularly monitored, transparent, and accountable.\n",
      "\n",
      "2. **Regulatory Frameworks**: The National Highway Traffic Safety Administration (NHTSA) and other agencies have rigorous standards and independent evaluations to ensure safety without stifling innovation.\n",
      "\n",
      "3. **Risk Management**: Organizations are using innovative solutions like risk assessments, auditing mechanisms, and ongoing monitoring to mitigate risks associated with AI.\n",
      "\n",
      "4. **Stakeholder Engagement**: Expanding opportunities for meaningful stakeholder engagement in the design of AI programs and services.\n",
      "\n",
      "5. **Research and Development**: The National Science Foundation (NSF) funds research to develop safe, secure, and effective AI systems. Programs support research on trustworthy, fair, and explainable AI algorithms and systems.\n",
      "\n",
      "6. **Ethical Frameworks**: Various government departments have developed specific ethical frameworks and principles to guide the development and use of AI.\n",
      "\n",
      "7. **Transparency and Accountability**: State legislatures and other bodies have placed strong transparency and validity requirements on the use of AI, particularly in sensitive areas like pretrial risk assessments.\n",
      "\n",
      "8. **NIST AI Risk Management Framework**: The National Institute of Standards and Technology (NIST) is developing a risk management framework to better manage risks posed by AI to individuals, organizations, and society.\n",
      "\n",
      "These strategies collectively aim to make AI safer for all humanity by ensuring that AI systems are developed and used responsibly, transparently, and ethically.\n",
      "\n",
      "If you have any more specific questions or need further details, feel free to ask!"
     ]
    }
   ],
   "source": [
    "await message(\"How can we make AI safer for all humanity?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634f0cc5-608d-4061-9543-7f022bca9701",
   "metadata": {},
   "source": [
    "## Adding conversation history\n",
    "The chain above doesn't keep track of the conversation history between the user and the bot. We also define a more \n",
    "complicated chain below which keeps track of the user's conversation memory and additionally attempts to ensure that\n",
    "the retrieved context is helpful in answering any questions from the user. \n",
    "\n",
    "The downside is that this uses **ConversationChain** which doesn't support async output streaming (Support for RunnableWithMessageHistory seems lacking so far)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c841fc0-f8dd-417f-b6f3-e5299418728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_of_rights = PyMuPDFLoader('Blueprint-for-an-AI-Bill-of-Rights.pdf').load()\n",
    "nist = PyMuPDFLoader('NIST.AI.600-1.pdf').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4ddfc29-f00a-4ce0-ba1f-ee0cfe200498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiktoken_len(text, model='gpt-4o'):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "be40bd65-f718-47bc-96cb-2b19492b537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "summary_chain = load_summarize_chain(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "25273f43-ce98-4f74-a2e0-0f465d5c9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_of_rights_text = \"\\n\\n\\n\".join([d.page_content for d in bill_of_rights])\n",
    "nist_text = \"\\n\\n\\n\".join([d.page_content for d in nist])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e18ae5-4cd8-4c0e-b538-e07f747e7e16",
   "metadata": {},
   "source": [
    "Let's look at the length of the combined documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c7010858-0cd4-4f1b-ae78-1fc4fa572a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44747"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiktoken_len(bill_of_rights_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b2e89d0d-add9-40ad-8c62-77dd09b8ef3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35902"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiktoken_len(nist_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa46a79-24ce-4fb6-957f-04b372a38647",
   "metadata": {},
   "source": [
    "These documents are small enough to fit in the model's context window. So let's quickly summarize them both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "92778342-1444-4ccd-b322-7d205224920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = summary_chain.invoke(bill_of_rights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "39a7c2b0-b010-4084-bfe2-eafefeb78f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_of_rights_summary = resp['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4eb4fbbb-9589-4410-84d6-165aeeadd305",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = summary_chain.invoke(nist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cf452f99-1c44-471b-bef4-af4467c5e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "nist_summary = resp['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6907ce07-dfc6-481a-9d7f-0e69e8b48ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_PROMPT = \"\"\"\n",
    "Please follow the following instructions: \n",
    "1. You are a helpful AI assistant who can help answer a user's questions regarding the documents AI Bill of Rights and\n",
    "NIST AI Risk Assessment Framework. \n",
    "2. A summary of both the documents is provided below. A user will occassionally ask\n",
    "you questions about these documents along with optional context to help you answer these questions. \n",
    "3. Please answer the user's questions based on the context they provide.\n",
    "4. Only if the user provides no context, rely on the summaries below. \n",
    "5. Let the user know you cannot answer the question if it is not based on their provided context or the summaries\n",
    "below.\n",
    "\n",
    "AI Bill of Rights Summary\n",
    "{bill_of_rights_summary}\n",
    "\n",
    "NIST AI Risk Assessment Framework Summary\n",
    "{nist_summary}\n",
    "\"\"\"\n",
    "\n",
    "rag_system_prompt = (ChatPromptTemplate.from_template(RAG_PROMPT)\n",
    "              .partial(bill_of_rights_summary=bill_of_rights_summary)\n",
    "              .partial(nist_summary=nist_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6572aa03-6771-4627-9bd0-5d99210539e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('rag_system_prompt.pkl', 'wb') as f:\n",
    "    pickle.dump(rag_system_prompt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "978fa47d-5fa8-4073-8aef-b97ee52244f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('rag_system_prompt.pkl', 'rb') as f:\n",
    "    rag_system_prompt = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86bb4c58-dfb3-4098-a3c0-c0d8c01b9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "retriever = QdrantVectorStore.from_existing_collection(\n",
    "    collection_name='ai_ethics_te3_small',\n",
    "    embedding=embedding,\n",
    "    url=os.environ.get('QDRANT_DB'),\n",
    "    api_key=os.environ.get('QDRANT_API_KEY')\n",
    ").as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80bd2f58-85b9-4edd-9772-f4e2dbd4249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "r = llm.invoke(rag_system_prompt.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63a5022-156f-4268-a093-a100577c8748",
   "metadata": {},
   "source": [
    "## A Simple Context Rewriting Chain\n",
    "Since we're building a conversational bot with some memory, it helps if the RAG chain doesn't return unhelpful context for the bot to answer. We'll define a simple chain component which inspects the question and the context and judges whether the context is actually helpful in answering the question. Otherwise it will return an empty context so the model can rely on summaries and its conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da2c8e96-f177-40ea-ae7f-787e37451434",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextOutput(BaseModel):\n",
    "    question: str = Field(description='The question from the user') \n",
    "    context: str = Field(description='The context for the question')\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=ContextOutput)\n",
    "instructions = \"\"\"\n",
    "1. You are to judge the question and context you see below and assess whether the context provided is actually helpful\n",
    "in answering the question. \n",
    "2. If the context is helpful in answering the question, please return the question and context \n",
    "without changes. \n",
    "3. Otherwise, please return the question without changes but an empty string as the context.\n",
    "4. Please follow the formatting instructions below as well\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    ('system', instructions)\n",
    ").partial(format_instructions=output_parser.get_format_instructions())\n",
    "\n",
    "#output_fixer = OutputFixingParser.from_llm(parser=output_parser, llm=ChatOpenAI())\n",
    "context_llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "context_chain = prompt | context_llm |  output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd991c6d-cc10-4164-b5b3-b81665dfde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0b4cf45-21ef-4b53-a13a-a3afe90beb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {'context': retriever, 'question': RunnablePassthrough()}\n",
    "    | context_chain\n",
    "    | {'context': lambda x: x.context, 'question': lambda x: x.question}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d756e4e-e5a0-4a1e-9e4a-e8b870f0884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message(message):\n",
    "    r = rag_chain.invoke(message)\n",
    "    return r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8950baff-efe1-4521-95fc-54b5e0dd84e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AI Bill of Rights, formally known as the \"Blueprint for an AI Bill of Rights,\" is a set of guidelines and principles proposed by the White House Office of Science and Technology Policy (OSTP) in the United States. Released in October 2022, it aims to protect the public from potential harms associated with artificial intelligence (AI) and automated systems. The document outlines five key principles designed to ensure that AI technologies are developed and used in ways that are ethical, fair, and respect individual rights.\n",
      "\n",
      "The five principles are:\n",
      "\n",
      "1. **Safe and Effective Systems**: AI systems should be developed and deployed in a manner that ensures they are safe and effective. This includes rigorous testing and monitoring to prevent harm and ensure that the systems function as intended.\n",
      "\n",
      "2. **Algorithmic Discrimination Protections**: AI systems should be designed and used in ways that prevent discrimination and bias. This involves implementing measures to ensure that AI does not perpetuate or exacerbate existing inequalities.\n",
      "\n",
      "3. **Data Privacy**: Individuals should have control over their personal data, and AI systems should be designed to protect privacy. This includes transparency about data collection and usage, as well as robust security measures to safeguard data.\n",
      "\n",
      "4. **Notice and Explanation**: People should be informed when an AI system is being used and understand how it impacts them. This principle emphasizes the importance of transparency and the need for clear explanations about how AI systems make decisions.\n",
      "\n",
      "5. **Human Alternatives, Consideration, and Fallback**: Individuals should have the option to opt out of AI-driven decisions and seek human alternatives. This ensures that people are not solely reliant on automated systems and can access human judgment when needed.\n",
      "\n",
      "The AI Bill of Rights serves as a framework to guide the development and deployment of AI technologies, aiming to ensure that they are aligned with democratic values and human rights. It is not a legally binding document but rather a set of recommendations intended to influence policy, industry practices, and public awareness.\n"
     ]
    }
   ],
   "source": [
    "print(message(\"What is the AI Bill of Rights?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6b74628b-abba-4108-8b2b-4a493184f061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data privacy provisions are measures and regulations designed to protect personal data from unauthorized access, use, disclosure, disruption, modification, or destruction. These provisions can be found in various laws, regulations, and best practices globally. Here are some key provisions for data privacy:\n",
      "\n",
      "1. **Consent**: Organizations must obtain explicit consent from individuals before collecting, using, or sharing their personal data. This consent must be informed, meaning individuals should understand what data is being collected and how it will be used.\n",
      "\n",
      "2. **Data Minimization**: Only the data necessary for a specific purpose should be collected and processed. This principle helps reduce the risk of unnecessary data exposure.\n",
      "\n",
      "3. **Purpose Limitation**: Personal data should only be collected for specified, explicit, and legitimate purposes and not further processed in a manner that is incompatible with those purposes.\n",
      "\n",
      "4. **Data Accuracy**: Organizations must ensure that personal data is accurate and kept up to date. Inaccurate data should be corrected or deleted without delay.\n",
      "\n",
      "5. **Storage Limitation**: Personal data should be kept in a form that permits identification of individuals for no longer than is necessary for the purposes for which the data is processed.\n",
      "\n",
      "6. **Security**: Organizations must implement appropriate technical and organizational measures to protect personal data against unauthorized or unlawful processing and against accidental loss, destruction, or damage.\n",
      "\n",
      "7. **Transparency**: Organizations must be transparent about their data processing activities. This includes providing clear and accessible information about how personal data is collected, used, shared, and protected.\n",
      "\n",
      "8. **Individual Rights**: Data privacy laws often grant individuals certain rights regarding their personal data, such as the right to access, correct, delete, or restrict the processing of their data. Individuals may also have the right to data portability and the right to object to data processing.\n",
      "\n",
      "9. **Accountability**: Organizations must be able to demonstrate compliance with data privacy laws and principles. This includes maintaining records of data processing activities and conducting regular audits.\n",
      "\n",
      "10. **Data Protection Officer (DPO)**: Some regulations, like the GDPR, require organizations to appoint a Data Protection Officer to oversee data protection strategies and ensure compliance with data privacy laws.\n",
      "\n",
      "11. **Breach Notification**: In the event of a data breach, organizations are often required to notify affected individuals and relevant authorities within a specified timeframe.\n",
      "\n",
      "12. **Cross-Border Data Transfers**: When personal data is transferred across borders, organizations must ensure that the data is adequately protected, often by using mechanisms such as standard contractual clauses, binding corporate rules, or adequacy decisions.\n",
      "\n",
      "13. **Children's Privacy**: Special provisions are often in place to protect the personal data of children, requiring parental consent for data processing activities involving minors.\n",
      "\n",
      "14. **Third-Party Processing**: Organizations must ensure that third-party processors comply with data privacy requirements and have appropriate safeguards in place.\n",
      "\n",
      "These provisions are encapsulated in various data privacy laws and regulations around the world, such as the General Data Protection Regulation (GDPR) in the European Union, the California Consumer Privacy Act (CCPA) in the United States, and the Personal Data Protection Act (PDPA) in Singapore, among others. Each jurisdiction may have specific requirements and nuances, but the overarching principles of data privacy remain consistent.\n"
     ]
    }
   ],
   "source": [
    "print(message(\"What are some of the provisions for data privacy?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c43be50f-006b-45fa-8eb0-9e7b074dacb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rise of artificial intelligence (AI) has brought about significant advancements and opportunities, but it also raises several concerns that individuals should be aware of. Here are some reasons why people might worry about AI:\n",
      "\n",
      "1. **Job Displacement**: AI and automation have the potential to replace a wide range of jobs, from manufacturing to white-collar positions. This could lead to significant unemployment and economic disruption if new job opportunities are not created at a similar pace.\n",
      "\n",
      "2. **Privacy Concerns**: AI systems often rely on large amounts of data to function effectively. This can lead to concerns about how personal data is collected, stored, and used, potentially infringing on individual privacy.\n",
      "\n",
      "3. **Bias and Discrimination**: AI systems can inadvertently perpetuate or even exacerbate existing biases present in the data they are trained on. This can lead to unfair treatment in areas such as hiring, lending, and law enforcement.\n",
      "\n",
      "4. **Security Risks**: AI can be used maliciously, for example, in the creation of deepfakes, automated hacking, or the development of autonomous weapons. These applications pose significant security risks at both individual and societal levels.\n",
      "\n",
      "5. **Lack of Accountability**: As AI systems become more complex, it can be difficult to understand how they make decisions. This lack of transparency can make it challenging to hold individuals or organizations accountable for the actions of AI systems.\n",
      "\n",
      "6. **Ethical Concerns**: The development and deployment of AI raise numerous ethical questions, such as the extent to which AI should be allowed to make decisions that affect human lives, and the moral implications of creating machines that can potentially surpass human intelligence.\n",
      "\n",
      "7. **Dependence on Technology**: Increasing reliance on AI can lead to a loss of certain skills and a dependency on technology that might be problematic if systems fail or are unavailable.\n",
      "\n",
      "8. **Economic Inequality**: The benefits of AI might not be evenly distributed, potentially leading to greater economic inequality. Those who control AI technologies could gain disproportionate power and wealth.\n",
      "\n",
      "9. **Autonomy and Control**: There is a fear that AI could eventually become so advanced that it might act in ways that are beyond human control, leading to scenarios where AI systems make decisions that are not aligned with human values or interests.\n",
      "\n",
      "10. **Regulatory Challenges**: The rapid pace of AI development often outstrips the ability of regulatory frameworks to keep up, leading to gaps in oversight and potential misuse of AI technologies.\n",
      "\n",
      "While AI has the potential to bring about many positive changes, it is important for individuals and society as a whole to address these concerns proactively to ensure that the development and deployment of AI technologies are aligned with ethical standards and public interest.\n"
     ]
    }
   ],
   "source": [
    "print(message(\"Why should individuals worry about AI?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
