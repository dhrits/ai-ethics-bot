{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df90de8-ed96-4ec9-93c9-5f54ab0e3e38",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook aims to build a searchable vecstore of the documents [Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People](https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf) and [National Institute of Standards and Technology (NIST) Artificial Intelligent Risk Management Framework](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600-1.pdf) in order to help allay the concerns of people who are anxious about the state of AI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef4dedb-83b6-4c65-a984-bad0c07ffd2b",
   "metadata": {},
   "source": [
    "We'll start with a set of imports to get ready for indexing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6aaa022a-c844-40ba-8f76-046ce2f99a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_openai.llms import OpenAI\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86cc0593-8df1-4735-a56c-9ca293c6d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyMuPDFLoader('Blueprint-for-an-AI-Bill-of-Rights.pdf')\n",
    "docs_bill_of_rights = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee3160e9-de23-48ab-b855-f32cf0144f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyMuPDFLoader('NIST.AI.600-1.pdf')\n",
    "docs_nist = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51c4efb9-b603-47c5-a6d4-e815a125c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = docs_bill_of_rights + docs_nist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1147646b-e5b7-45c5-9f99-e81c6b062d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28893d5-611b-4712-86e2-76cb5487db44",
   "metadata": {},
   "source": [
    "## Text splitting\n",
    "Next we take these documents and split them up into chunks for easy retrieval from a vectorstore. Without knowing much about these documents, a `RecursiveCharacterTextSplitter` seems like the most obvious choice. Even the Langchain website recommends this strategy if the data is mostly unstructured (which these PDF documents are) and there's no additional structure we know about it. We'll make use of `text-embedding-3-small` as the default choice of openai embeddings for maximal performance. This is from the family of the highest performance embedding models from OpenAI. Using the `small` embeddings trades off performance and cost.\n",
    "\n",
    "Since we're using `text-embedding-3-small` model, we'll also define a length function that accounts for tokens from use of this model while splitting up the text into chunks. \n",
    "\n",
    "For the future, a chunking strategy we could test out the experimental `SemanticChunker` which further combines sentences if they are semantically similar. But this is more of a risky choice so we'll stick with the default for now and might make use of MDD to determine if `SemanticChunker` is better later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad93c24a-c5d8-49ab-96c1-4254a5c57f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiktoken_len(text, model='text-embedding-3-small'):\n",
    "    embedding = tiktoken.encoding_for_model(model)\n",
    "    query = embedding.encode(text)\n",
    "    return len(query)\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=200,\n",
    "    length_function=tiktoken_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f53fadf-a082-4e4e-a23a-e8ee74692e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3378c36a-29ff-4b9b-9d33-1595fd52fa73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be82fa34-5c2e-4586-b65c-e817e0791edf",
   "metadata": {},
   "source": [
    "## Build Vectorstore from Embeddings\n",
    "Next we take these split documents and build out a vectorstore using `Qdrant`, a fairly high performant and flexible vectorstore. We'll continue to use `text-embedding-3-large` as the embedding function to store documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c44ac394-797d-4ca8-a2af-44708b679302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv; load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "551eca15-9045-4868-95f6-5d2276e2d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2604cc-5b27-4ace-a921-0c0422df4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\n",
    "    url=os.environ.get('QDRANT_DB'),\n",
    "    api_key=os.environ.get('QDRANT_API_KEY'),\n",
    ")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"ai_ethics_te3_small\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d9fbda8-bc24-41ec-b2ba-52d6245fe833",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"ai_ethics_te3_small\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55c83411-47ad-4854-ac02-f89f37baacbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_documents(store, documents):\n",
    "    for i in range(0, len(documents), 10):\n",
    "        batch = documents[i:i+10]\n",
    "        vector_store.add_documents(\n",
    "            documents=batch,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7112a4-80c7-4168-9065-189c934374d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_documents(vector_store, split_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ddef8b-a655-44e2-a57c-7f7ad590d173",
   "metadata": {},
   "source": [
    "### Also add a store for text-embeddings-3-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "08ec6cfa-7448-4ac6-b2c8-6b72e77b31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=200,\n",
    "    length_function=partial(tiktoken_len, model='text-embedding-3-large')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bded97b1-8962-4f32-bb4c-d51f1b2ed888",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb4f17b6-26bf-4f15-91c7-0ea8d4ba7345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_collection(\n",
    "    collection_name=\"ai_ethics_te3_large\",\n",
    "    vectors_config=VectorParams(size=3072, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b0f4c92-095f-408c-91f5-288f5659dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"ai_ethics_te3_large\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fd35bc15-9e58-4f08-bd29-4eb57c14dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_documents(vector_store, split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2585f311-b654-422c-a24b-53d238ef36e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
